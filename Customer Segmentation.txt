### Step 1: Import Libraries and Load Data

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Load dataset
data = pd.read_csv('customer_data.csv')

# Selecting relevant features for clustering
features = ['Annual_Income', 'Spending_Score', 'Age']
X = data[features]

### Step 2: Preprocess Data

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

### Step 3: Find Optimal Number of Clusters using Elbow Method

distortions = []
k_range = range(1, 11)
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    distortions.append(kmeans.inertia_)

plt.figure(figsize=(8, 5))
plt.plot(k_range, distortions, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Distortion')
plt.title('Elbow Method for Optimal k')
plt.show()

### Step 4: Train K-Means Model

optimal_k = 4  # Based on elbow method
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
kmeans.fit(X_scaled)
data['Cluster'] = kmeans.labels_

### Step 5: Visualize Clusters

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
data['PCA1'] = X_pca[:, 0]
data['PCA2'] = X_pca[:, 1]

plt.figure(figsize=(8, 6))
sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=data, palette='viridis')
plt.title('Customer Segmentation Clusters')
plt.show()

### Step 6: Save Model for Deployment

import pickle
pickle.dump(kmeans, open('kmeans_model.pkl', 'wb'))
pickle.dump(scaler, open('scaler.pkl', 'wb'))

### Step 7: Create API for Model Deployment

from flask import Flask, request, jsonify

app = Flask(__name__)
kmeans_model = pickle.load(open("kmeans_model.pkl", "rb"))
scaler_model = pickle.load(open("scaler.pkl", "rb"))

@app.route('/predict', methods=['POST'])
def predict():
    try:
        data = request.get_json()
        features = np.array(data['features']).reshape(1, -1)
        features_scaled = scaler_model.transform(features)
        cluster = kmeans_model.predict(features_scaled)[0]
        return jsonify({'Cluster': int(cluster)})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
